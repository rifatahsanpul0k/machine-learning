{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7dfbef",
   "metadata": {},
   "source": [
    "# Data Preprocessing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7d86f",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e67c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40663a06",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b043ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "\n",
    "df.drop(['deck','alive','embark_town','who','adult_male','parch','fare','embarked'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X = df.drop(['survived'], axis=1).values\n",
    "y = df['survived'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c244adc",
   "metadata": {},
   "source": [
    "### Taking care of the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bf14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 'male' 22.0 1 'Third' False]\n",
      " [1 'female' 38.0 1 'First' False]\n",
      " [3 'female' 26.0 0 'Third' True]\n",
      " ...\n",
      " [3 'female' 29.69869565217391 1 'Third' False]\n",
      " [1 'male' 26.0 0 'First' True]\n",
      " [3 'male' 32.0 0 'Third' True]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X[:,2:3] = imputer.fit_transform(X[:,2:3])\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b3ac9",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597a4b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])],remainder='passthrough') # constructor initialization\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc5a1f",
   "metadata": {},
   "source": [
    "### Encoding the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39791a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 ... 22.0 1 0]\n",
      " [1.0 0.0 0.0 ... 38.0 1 0]\n",
      " [0.0 0.0 1.0 ... 26.0 0 1]\n",
      " ...\n",
      " [0.0 0.0 1.0 ... 29.69869565217391 1 0]\n",
      " [1.0 0.0 0.0 ... 26.0 0 1]\n",
      " [0.0 0.0 1.0 ... 32.0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "X[:,7] = le.fit_transform(X[:,7])\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e252d",
   "metadata": {},
   "source": [
    "### Splitting data into the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d821db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, ..., 22.0, 1, 0],\n",
       "       [1.0, 0.0, 0.0, ..., 38.0, 1, 0],\n",
       "       [0.0, 0.0, 1.0, ..., 26.0, 0, 1],\n",
       "       ...,\n",
       "       [0.0, 0.0, 1.0, ..., 29.69869565217391, 1, 0],\n",
       "       [1.0, 0.0, 0.0, ..., 26.0, 0, 1],\n",
       "       [0.0, 0.0, 1.0, ..., 32.0, 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01468947",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce353f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, ..., -0.010408910095821986, 1, 0],\n",
       "       [0.0, 0.0, 1.0, ..., -0.010408910095821986, 1, 0],\n",
       "       [0.0, 0.0, 1.0, ..., 0.16703628173832194, 0, 1],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 1.4007379744450077, 0, 1],\n",
       "       [0.0, 0.0, 1.0, ..., -0.6811336319975244, 2, 0],\n",
       "       [1.0, 0.0, 0.0, ..., -0.6811336319975244, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,5:6] = sc.fit_transform(X_train[:,5:6])\n",
    "X_test[:,5:6] = sc.fit_transform(X_test[:,5:6])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
